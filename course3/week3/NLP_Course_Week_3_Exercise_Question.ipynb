{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"NLP_Course_Week_3_Exercise_Question.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"zX4Kg8DUTKWO","colab_type":"code","colab":{}},"source":["#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","# https://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"hmA6EzkQJ5jt","colab":{},"executionInfo":{"status":"ok","timestamp":1600905294413,"user_tz":240,"elapsed":2067,"user":{"displayName":"saitejas mopuri","photoUrl":"","userId":"14700967711072540579"}}},"source":["import json\n","import tensorflow as tf\n","import csv\n","import random\n","import numpy as np\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.keras import regularizers\n","\n","\n","embedding_dim = 100\n","max_length = 16\n","trunc_type='post'\n","padding_type='post'\n","oov_tok = \"<OOV>\"\n","training_size= 16000\n","test_portion=.1\n","\n","corpus = []\n"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bM0l_dORKqE0","colab":{"base_uri":"https://localhost:8080/","height":220},"executionInfo":{"status":"ok","timestamp":1600905302171,"user_tz":240,"elapsed":9753,"user":{"displayName":"saitejas mopuri","photoUrl":"","userId":"14700967711072540579"}},"outputId":"b04379bc-5f1b-4489-e859-2b7ed9dee852"},"source":["# Note that I cleaned the Stanford dataset to remove LATIN1 encoding to make it easier for Python CSV reader\n","# You can do that yourself with:\n","# iconv -f LATIN1 -t UTF8 training.1600000.processed.noemoticon.csv -o training_cleaned.csv\n","# I then hosted it on my site to make it easier to use in this notebook\n","\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/training_cleaned.csv \\\n","    -O /tmp/training_cleaned.csv\n","\n","num_sentences = 0\n","\n","with open(\"/tmp/training_cleaned.csv\") as csvfile:\n","    reader = csv.reader(csvfile, delimiter=',')\n","    for row in reader:\n","      # Your Code here. Create list items where the first item is the text, found in row[5], and the second is the label. Note that the label is a '0' or a '4' in the text. When it's the former, make\n","      # your label to be 0, otherwise 1. Keep a count of the number of sentences in num_sentences\n","        list_item=[]\n","        list_item.append(row[5])\n","        list_item.append(int(row[0]))\n","        # YOUR CODE HERE\n","        num_sentences = num_sentences + 1\n","        corpus.append(list_item)\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-09-23 23:54:54--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/training_cleaned.csv\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.195.128, 74.125.142.128, 74.125.20.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.195.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 238942690 (228M) [application/octet-stream]\n","Saving to: ‘/tmp/training_cleaned.csv’\n","\n","/tmp/training_clean 100%[===================>] 227.87M   102MB/s    in 2.2s    \n","\n","2020-09-23 23:54:56 (102 MB/s) - ‘/tmp/training_cleaned.csv’ saved [238942690/238942690]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"3kxblBUjEUX-","colab":{"base_uri":"https://localhost:8080/","height":72},"executionInfo":{"status":"ok","timestamp":1600905302180,"user_tz":240,"elapsed":9746,"user":{"displayName":"saitejas mopuri","photoUrl":"","userId":"14700967711072540579"}},"outputId":"1c9d2c9d-2601-483e-f29c-8ab21653c8f3"},"source":["print(num_sentences)\n","print(len(corpus))\n","print(corpus[1])\n","\n","# Expected Output:\n","# 1600000\n","# 1600000\n","# [\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\", 0]"],"execution_count":3,"outputs":[{"output_type":"stream","text":["1600000\n","1600000\n","[\"is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!\", 0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ohOGz24lsNAD","colab":{},"executionInfo":{"status":"ok","timestamp":1600905304521,"user_tz":240,"elapsed":12079,"user":{"displayName":"saitejas mopuri","photoUrl":"","userId":"14700967711072540579"}}},"source":["sentences=[]\n","labels=[]\n","random.shuffle(corpus)\n","for x in range(training_size):\n","    sentences.append(corpus[x][0])\n","    labels.append(corpus[x][1])\n","\n","\n","tokenizer = Tokenizer()\n","tokenizer.fit_on_texts(sentences)\n","\n","word_index = tokenizer.word_index\n","vocab_size=len(word_index)\n","\n","sequences = tokenizer.texts_to_sequences(sentences)\n","padded = pad_sequences(sequences, padding='post', maxlen=vocab_size)\n","\n","split = int(test_portion * training_size)\n","\n","test_sequences = padded[0:split]\n","training_sequences = padded[split:]\n","test_labels = labels[0:split]\n","training_labels = labels[split:]"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gIrtRem1En3N","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1600905304526,"user_tz":240,"elapsed":12072,"user":{"displayName":"saitejas mopuri","photoUrl":"","userId":"14700967711072540579"}},"outputId":"3a1465bf-1cdb-4a20-eec6-db642e6fbf0b"},"source":["print(vocab_size)\n","print(word_index['i'])\n","# Expected Output\n","# 138858\n","# 1"],"execution_count":5,"outputs":[{"output_type":"stream","text":["26552\n","1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"C1zdgJkusRh0","colab":{"base_uri":"https://localhost:8080/","height":220},"executionInfo":{"status":"ok","timestamp":1600905318664,"user_tz":240,"elapsed":26198,"user":{"displayName":"saitejas mopuri","photoUrl":"","userId":"14700967711072540579"}},"outputId":"10099b55-1660-4cb9-bffd-81172dd58939"},"source":["# Note this is the 100 dimension version of GloVe from Stanford\n","# I unzipped and hosted it on my site to make this notebook easier\n","!wget --no-check-certificate \\\n","    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt \\\n","    -O /tmp/glove.6B.100d.txt\n","embeddings_index = {};\n","with open('/tmp/glove.6B.100d.txt') as f:\n","    for line in f:\n","        values = line.split();\n","        word = values[0];\n","        coefs = np.asarray(values[1:], dtype='float32');\n","        embeddings_index[word] = coefs;\n","\n","embeddings_matrix = np.zeros((vocab_size+1, embedding_dim));\n","for word, i in word_index.items():\n","    embedding_vector = embeddings_index.get(word);\n","    if embedding_vector is not None:\n","        embeddings_matrix[i] = embedding_vector;"],"execution_count":6,"outputs":[{"output_type":"stream","text":["--2020-09-23 23:55:04--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/glove.6B.100d.txt\n","Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.142.128, 173.194.203.128, 74.125.197.128, ...\n","Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.142.128|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 347116733 (331M) [text/plain]\n","Saving to: ‘/tmp/glove.6B.100d.txt’\n","\n","/tmp/glove.6B.100d. 100%[===================>] 331.04M  90.3MB/s    in 3.7s    \n","\n","2020-09-23 23:55:08 (90.3 MB/s) - ‘/tmp/glove.6B.100d.txt’ saved [347116733/347116733]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"71NLk_lpFLNt","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"05acb2d0-abe1-4e42-e4f4-886e0dd1f104"},"source":["print(len(embeddings_matrix))\n","# Expected Output\n","# 138859"],"execution_count":null,"outputs":[{"output_type":"stream","text":["26827\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uNL0E2LYvySg","colab_type":"code","colab":{}},"source":["from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Conv2D, RNN, GRU, Embedding, MaxPool1D, Flatten, Bidirectional"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"spSiGafH1EDC","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600905379660,"user_tz":240,"elapsed":333,"user":{"displayName":"saitejas mopuri","photoUrl":"","userId":"14700967711072540579"}}},"source":[""],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"BsFjizsqxgZ0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":92},"outputId":"3c46ec14-790d-4167-afa1-0c2a668fe0ce"},"source":["#model 1 using DNN & LSTM\n","model_1 = Sequential()\n","\n","model_1.add(Embedding(vocab_size+1, embedding_dim, \n","                      input_length=max_length, weights=[embeddings_matrix], trainable=False))\n","\n","model_1.add(Bidirectional(LSTM(64)))\n","\n","model_1.add(Dense(64, activation='relu'))\n","\n","model_1.add(Dense(1, activation='relu'))\n","\n","model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","num_epochs = 50\n","\n","training_labels = np.array(training_labels)\n","test_labels = np.array(test_labels)\n","\n","history = model_1.fit(training_sequences, training_labels, epochs=num_epochs, validation_data=(test_sequences, test_labels), verbose=2)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","WARNING:tensorflow:Model was constructed with shape (None, 16) for input Tensor(\"embedding_1_input:0\", shape=(None, 16), dtype=float32), but it was called on an input with incompatible shape (32, 26826).\n","WARNING:tensorflow:Model was constructed with shape (None, 16) for input Tensor(\"embedding_1_input:0\", shape=(None, 16), dtype=float32), but it was called on an input with incompatible shape (32, 26826).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5U-rNoji5dfD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":276},"outputId":"f10e2c65-ef5f-4e11-d18f-346768118276"},"source":["model_1.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, 16, 100)           2682700   \n","_________________________________________________________________\n","dense (Dense)                (None, 16, 64)            6464      \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 16, 1)             65        \n","=================================================================\n","Total params: 2,689,229\n","Trainable params: 6,529\n","Non-trainable params: 2,682,700\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iKKvbuEBOGFz","colab":{}},"source":["model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size+1, embedding_dim, input_length=max_length, weights=[embeddings_matrix], trainable=False),\n","    # YOUR CODE HERE - experiment with combining different types, such as convolutions and LSTMs\n","])\n","model.compile(# YOUR CODE HERE)\n","model.summary()\n","\n","num_epochs = 50\n","history = model.fit(training_sequences, training_labels, epochs=num_epochs, validation_data=(test_sequences, test_labels), verbose=2)\n","\n","print(\"Training Complete\")\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"qxju4ItJKO8F","colab":{}},"source":["import matplotlib.image  as mpimg\n","import matplotlib.pyplot as plt\n","\n","#-----------------------------------------------------------\n","# Retrieve a list of list results on training and test data\n","# sets for each training epoch\n","#-----------------------------------------------------------\n","acc=history.history['accuracy']\n","val_acc=history.history['val_accuracy']\n","loss=history.history['loss']\n","val_loss=history.history['val_loss']\n","\n","epochs=range(len(acc)) # Get number of epochs\n","\n","#------------------------------------------------\n","# Plot training and validation accuracy per epoch\n","#------------------------------------------------\n","plt.plot(epochs, acc, 'r')\n","plt.plot(epochs, val_acc, 'b')\n","plt.title('Training and validation accuracy')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Accuracy\")\n","plt.legend([\"Accuracy\", \"Validation Accuracy\"])\n","\n","plt.figure()\n","\n","#------------------------------------------------\n","# Plot training and validation loss per epoch\n","#------------------------------------------------\n","plt.plot(epochs, loss, 'r')\n","plt.plot(epochs, val_loss, 'b')\n","plt.title('Training and validation loss')\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"Loss\")\n","plt.legend([\"Loss\", \"Validation Loss\"])\n","\n","plt.figure()\n","\n","\n","# Expected Output\n","# A chart where the validation loss does not increase sharply!"],"execution_count":null,"outputs":[]}]}